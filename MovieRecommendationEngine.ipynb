{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rating some movies\n",
    "#### To make recommendation for you, we are going to learn your taste by asking you to rate a few movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you've already rated the movies. Overwrite ratings (y/N)? y\n",
      "Please rate the following movie (1-5 (best), or 0 if not seen): \n",
      "Toy Story (1995): `1\n",
      "Please rate the following movie (1-5 (best), or 0 if not seen): \n",
      "Toy Story (1995): 1\n",
      "Independence Day (a.k.a. ID4) (1996): 5\n",
      "Dances with Wolves (1990): 3\n",
      "Star Wars: Episode VI - Return of the Jedi (1983): 5\n",
      "Mission: Impossible (1996): 5\n",
      "Ace Ventura: Pet Detective (1994): 5\n",
      "Die Hard: With a Vengeance (1995): 5\n",
      "Batman Forever (1995): 5\n",
      "Pretty Woman (1990): 1\n",
      "Men in Black (1997): 5\n",
      "Dumb & Dumber (1994): 2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import remove, removedirs\n",
    "from os.path import dirname, join, isfile\n",
    "from time import time\n",
    "\n",
    "topMovies = \"\"\"1,Toy Story (1995)\n",
    "780,Independence Day (a.k.a. ID4) (1996)\n",
    "590,Dances with Wolves (1990)\n",
    "1210,Star Wars: Episode VI - Return of the Jedi (1983)\n",
    "648,Mission: Impossible (1996)\n",
    "344,Ace Ventura: Pet Detective (1994)\n",
    "165,Die Hard: With a Vengeance (1995)\n",
    "153,Batman Forever (1995)\n",
    "597,Pretty Woman (1990)\n",
    "1580,Men in Black (1997)\n",
    "231,Dumb & Dumber (1994)\"\"\"\n",
    "\n",
    "parentDir = os.path.abspath('')\n",
    "ratingsFile = join(parentDir, \"personalRatings.txt\")\n",
    "\n",
    "if isfile(ratingsFile):\n",
    "    r = input(\"Looks like you've already rated the movies. Overwrite ratings (y/N)? \")\n",
    "    if r and r[0].lower() == \"y\":\n",
    "        remove(ratingsFile)\n",
    "    else:\n",
    "        sys.exit()\n",
    "\n",
    "prompt = \"Please rate the following movie (1-5 (best), or 0 if not seen): \"\n",
    "print(prompt)\n",
    "\n",
    "now = int(time())\n",
    "n = 0\n",
    "\n",
    "f = open(ratingsFile, 'w')\n",
    "for line in topMovies.split(\"\\n\"):\n",
    "    ls = line.strip().split(\",\")\n",
    "    valid = False\n",
    "    while not valid:\n",
    "        rStr = input(ls[1] + \": \")\n",
    "        r = int(rStr) if rStr.isdigit() else -1\n",
    "        if r < 0 or r > 5:\n",
    "            print(prompt)\n",
    "        else:\n",
    "            valid = True\n",
    "            if r > 0:\n",
    "                f.write(\"0::%s::%d::%d\\n\" % (ls[0], r, now))\n",
    "                n += 1\n",
    "f.close()\n",
    "\n",
    "if n == 0:\n",
    "    print(\"No rating provided!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# All the imports needed for the project\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "import math\n",
    "from math import sqrt\n",
    "from operator import add\n",
    "from os.path import join, isfile, dirname\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods need to parse data to a RDD\n",
    "def parseMyRating(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp,\n",
    "    for my movie ratings genereated from the txt file above.\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[3]) % 10, (int(fields[0]), int(fields[1]), float(fields[2]))\n",
    "\n",
    "def parseMovieRatings(line):\n",
    "    \"\"\"\n",
    "    Parses a rating record in MovieLens format userId::movieId::rating::timestamp,\n",
    "    for movie ratings generated from the ratings.dat file.\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), int(fields[1]), float(fields[2])\n",
    "\n",
    "def parseMovie(line):\n",
    "    \"\"\"\n",
    "    Parses a movie record in MovieLens format movieId::movieTitle,\n",
    "    for movies generated from the movies.dat file.\n",
    "    \"\"\"\n",
    "    fields = line.strip().split(\"::\")\n",
    "    return int(fields[0]), fields[1]\n",
    "\n",
    "def loadRatings(ratingsFile):\n",
    "    \"\"\"\n",
    "    Load ratings from file.\n",
    "    \"\"\"\n",
    "    if not isfile(ratingsFile):\n",
    "        print(\"File %s does not exist.\" % ratingsFile)\n",
    "        sys.exit(1)\n",
    "    f = open(ratingsFile, 'r')\n",
    "    ratings = filter(lambda r: r[2] > 0, [parseMyRating(line)[1] for line in f])\n",
    "    f.close()\n",
    "    if not ratings:\n",
    "        print(\"No ratings provided.\")\n",
    "        sys.exit(1)\n",
    "    else:\n",
    "        return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 12:42:16 WARN Utils: Your hostname, MSI resolves to a loopback address: 127.0.1.1; using 172.22.5.230 instead (on interface wifi0)\n",
      "21/10/07 12:42:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/10/07 12:42:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # set up environment for spark\n",
    "    spark = SparkSession.builder \\\n",
    "   .master(\"local\") \\\n",
    "   .appName(\"Movie Recommendation Engine\") \\\n",
    "   .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "   .getOrCreate()\n",
    "\n",
    "    sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    # load personal ratings\n",
    "    myRatings = loadRatings(os.path.abspath('./personalRatings.txt'))\n",
    "    # Create an RDD of myRatings\n",
    "    myRatingsRDD = sc.parallelize(myRatings)\n",
    "    # Creates a DF with userID, movieID and movieRating\n",
    "    myRatingsDF = myRatingsRDD.map(lambda line: Row(userId=line[0], movieId=line[1], movieRating=line[2])).toDF()\n",
    "    \n",
    "    # load ratings and movie titles\n",
    "    # Directory of the file\n",
    "    movieLensHomeDir = os.path.abspath('.')\n",
    "\n",
    "    # Create an RDD of ratings\n",
    "    ratingsRDD = sc.textFile(join(movieLensHomeDir, \"ratings.dat\")).map(parseMovieRatings)\n",
    "    # Creats a DF with userID, movieID and movieRating\n",
    "    ratingsDF = ratingsRDD.map(lambda line: Row(userId=line[0], movieId=line[1], movieRating=line[2])).toDF()\n",
    "\n",
    "    # Create an RDD of movies     \n",
    "    movies = sc.textFile(join(movieLensHomeDir, \"movies.dat\")).map(parseMovie)\n",
    "    # creates a DF of movies with movieID and movieName\n",
    "    moviesDF = movies.map(lambda line: Row(movieId=line[0], movieName=line[1])).toDF()\n",
    "    \n",
    "    # Joins my ratings with all users ratings so data can be used in the algorithm     \n",
    "    jointRatingsDF = ratingsDF.union(myRatingsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/07 12:42:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/10/07 12:42:39 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "21/10/07 12:42:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "21/10/07 12:42:40 WARN LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "[Stage 84:=====================================================>(197 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7537907559876704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    # your code here\n",
    "    # Creates an ALS algorithm with 10 iterations, regParams of 0.1 with specifies the regulrization parameter,\n",
    "    # rank 6 is the number of features to use, the three columns to use are userId, movieId, and movieRating for the\n",
    "    # algorithm, coldStartStrategy drops any rows with a NaN value.\n",
    "    # All code below is found on the Pyspark Library information\n",
    "    als = ALS(maxIter=10, regParam=0.1, rank=6, userCol=\"userId\",\n",
    "              itemCol = \"movieId\", ratingCol=\"movieRating\", coldStartStrategy = \"drop\")\n",
    "    # Create a train and test data set splitting  the data 80/20% split respectively.\n",
    "    # The jointRatingsDF is used as it has all the user ratings including my own\n",
    "    train, test = jointRatingsDF.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # Training the Model using the train dataset\n",
    "    alsModel = als.fit(train)\n",
    "    # Generating Predictions using the test dataset\n",
    "    prediction = alsModel.transform(test)\n",
    "    \n",
    "    # the evaluator is used to produce the cost function in this case Mean Squarred Error\n",
    "    evaluator = RegressionEvaluator(metricName=\"mse\", labelCol=\"movieRating\",  predictionCol=\"prediction\")\n",
    "    # Mse is generated from the predictions data\n",
    "    mse = evaluator.evaluate(prediction)\n",
    "    # The mse is printed\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                            |\n",
      "+------+-------------------------------------------------------------------------------------------+\n",
      "|1580  |[{572, 4.5322785}, {989, 4.3725634}, {1851, 4.3330235}, {557, 4.2620735}, {787, 4.22304}]  |\n",
      "|4900  |[{572, 6.0900874}, {3236, 5.431673}, {1851, 5.3946605}, {3233, 5.386013}, {318, 5.2496533}]|\n",
      "|5300  |[{557, 5.4200816}, {989, 5.304091}, {2309, 5.244132}, {787, 5.1481786}, {1420, 5.030448}]  |\n",
      "|471   |[{2309, 4.734953}, {1780, 4.7279377}, {989, 4.7174015}, {3236, 4.710863}, {1851, 4.684157}]|\n",
      "|1591  |[{572, 5.887376}, {557, 5.773006}, {989, 5.6165886}, {2562, 5.4845977}, {787, 5.3916078}]  |\n",
      "+------+-------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                            |\n",
      "+------+-------------------------------------------------------------------------------------------+\n",
      "|0     |[{3382, 8.316638}, {776, 6.8689036}, {2765, 6.730685}, {2197, 6.3872523}, {1793, 6.356622}]|\n",
      "+------+-------------------------------------------------------------------------------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    # Generate recommend movies 5 movies for all users in the dataset\n",
    "    recommended_movie_df = alsModel.recommendForAllUsers(5)\n",
    "    # print the recommended movies for 5 users and the False signifys not to hide the data\n",
    "    print(recommended_movie_df.show(5, False))\n",
    "    # Filter the recommended movies df to only show movies for my user, user 0\n",
    "    recommended_movie_df = recommended_movie_df[recommended_movie_df['userId']==0]\n",
    "    # print the new updated recommended movies df with only my user\n",
    "    print(recommended_movie_df.show(1, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 260:==================================================>  (191 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(movieId=3382, rating=8.316637992858887)\n",
      "Row(movieId=776, rating=6.868903636932373)\n",
      "Row(movieId=2765, rating=6.730685234069824)\n",
      "Row(movieId=2197, rating=6.387252330780029)\n",
      "Row(movieId=1793, rating=6.356622219085693)\n",
      "+-------+-----------------+\n",
      "|movieId|           rating|\n",
      "+-------+-----------------+\n",
      "|   3382|8.316637992858887|\n",
      "|    776|6.868903636932373|\n",
      "|   2765|6.730685234069824|\n",
      "|   2197|6.387252330780029|\n",
      "|   1793|6.356622219085693|\n",
      "+-------+-----------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    # Create a movies array which we can pass in movies that we recommended by the system\n",
    "    moviesArray = []\n",
    "    \n",
    "    # for the column in the recommended movie df create a flat list using the first row, [0]\n",
    "    for row in recommended_movie_df.select(\"recommendations\").rdd.flatMap(list).collect()[0]:\n",
    "        # Print the row to be able to see the data generated\n",
    "        print(row)\n",
    "        # Add movies to the array using the movieId and movie rating generated from the algorithm\n",
    "        moviesArray.append((row['movieId'], row['rating']))\n",
    "    # Generate a RDD using the movies Array and give it columns movieId and rating\n",
    "    moviesGenerated = map(lambda x : Row(movieId=x[0], rating=x[1]), moviesArray)\n",
    "    # Create a DF using the moviesGenerated and pass it in columns movieId and ratings\n",
    "    moviesGeneratedDF=spark.createDataFrame(moviesGenerated, [\"movieId\"],[\"ratings\"])\n",
    "\n",
    "    # Print the new DF showing the movieId and rating\n",
    "    print(moviesGeneratedDF.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 264:=============================>                       (113 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+---------------------------+\n",
      "|movieId|rating           |movieId|movieName                  |\n",
      "+-------+-----------------+-------+---------------------------+\n",
      "|3382   |8.316637992858887|3382   |Song of Freedom (1936)     |\n",
      "|776    |6.868903636932373|776    |Babyfever (1994)           |\n",
      "|2765   |6.730685234069824|2765   |Acid House, The (1998)     |\n",
      "|2197   |6.387252330780029|2197   |Firelight (1997)           |\n",
      "|1793   |6.356622219085693|1793   |Welcome to Woop-Woop (1997)|\n",
      "+-------+-----------------+-------+---------------------------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 264:==========================================>          (162 + 1) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    # Create an a new DF joining moviesDF with moviesGeneratedDF, this way we can get the name of the movies generated\n",
    "    # Join the DFs on movieId using a left join\n",
    "    recommendMovies = moviesGeneratedDF.join(moviesDF, moviesGeneratedDF.movieId == moviesDF.movieId, how='left')\n",
    "    # Order the recommendMovies DF by rating so the highest rated is at the top and lowest at the bottom\n",
    "    recommendMovies = recommendMovies.orderBy('rating', ascending=False)\n",
    "    # Print out the new DF showing the result\n",
    "    print(recommendMovies.show(5,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 270:==========================================>          (160 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Song of Freedom (1936)\n",
      "2: Babyfever (1994)\n",
      "3: Acid House, The (1998)\n",
      "4: Firelight (1997)\n",
      "5: Welcome to Woop-Woop (1997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "    # X is = 1 so we can use it in the formatting of the results\n",
    "    x = 1\n",
    "    # Loop through the recommendMovies using the movie Name\n",
    "    for row in recommendMovies.select(\"movieName\").rdd.flatMap(list).collect():\n",
    "        # Create a temporary variable to format the string using the x and the movie name\n",
    "        var = str(x) + \": \"+ row\n",
    "        # Finally print out the desired output in the form\n",
    "        # 1: Song of Freedom (1936) for example\n",
    "        print(var)\n",
    "        # Increment x for the next movie\n",
    "        x = x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # clean up and stop the spark instance\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
